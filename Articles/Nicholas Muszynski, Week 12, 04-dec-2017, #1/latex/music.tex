\documentclass{article}
\begin{document}



\title{Rhythmic Interaction in VR: Interplay Between Sound Design and Editing}
\author{Nicholas Muszynski}
\date{December 15, 2017}

\maketitle

\textbf{Summary}
\newline

This article reviews concepts and techniques of video and sound editing for cinematic virtual reality experiences. When a user is able to change what direction they are looking at, a major focus becomes how the sound is produced based on the direction the user is looking and the source of the sound. Another factor that is considered is how the sound would carry within the virtual environment that the user is within, such as a bathroom, a hallway, a cavern, or an auditorium. Three concepts of rhythm are explored for virtual reality: physical rhythm (physical interactions such as punching sounds from a fight), emotional rhythm (typically focusing on the tempo of physical rhythm), and event rhythm (the volume and tempo of the sound as a whole across various defining events). By utilizing these three rhythms, and modifying them according to the virtual environment a user is in, the overall cinematic experience will have a much greater impact if brought together correctly, and providing audiences with a more enjoyable and satisfying experience.

\nocite{musicCite}

\bibliography{music}
\bibliographystyle{ieeetr}

\end{document}